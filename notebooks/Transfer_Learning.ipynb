{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11d5c6b0-5032-4dff-a423-a1a792da9e63",
   "metadata": {},
   "source": [
    "### [Transfer Learning in Time Series Analysis](https://medium.com/@kylejones_47003/transfer-learning-in-time-series-analysis-4b7f1d1f4bfd)\n",
    "\n",
    "> Modern neural networks can learn temporal patterns from one domain and apply them to another, dramatically reducing the data needed for accurate predictions. This transfer of knowledge enables organizations to leverage existing models for new applications, from energy forecasting to healthcare monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefcc3a2-522c-4219-a4f6-2f3bdbe5791b",
   "metadata": {},
   "source": [
    "Transfer learning represents a paradigm shift in how we approach time series modeling. Traditional time series analysis requires substantial data from the specific domain of interest.\n",
    "\n",
    "The application of transfer learning to time series data operates through several key mechanisms. Feature-based transfer learning extracts meaningful representations from source time series data that can be applied to target domains.\n",
    "\n",
    "Parameter-based transfer learning, alternatively, reuses parts of a trained model’s architecture or parameters, fine-tuning them for the new task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72f4b5d-e6ba-454c-9222-c07cfdb9c354",
   "metadata": {},
   "source": [
    "##### Instance-based Transfer Learning\n",
    "\n",
    "Instance-based transfer learning selectively uses samples from the source domain to augment learning in the target domain. This approach proves particularly valuable when dealing with rare events or anomalies in time series data.\n",
    "\n",
    "The key challenge lies in identifying which instances from the source domain remain relevant to the target problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f3c9e-b8b0-41d6-a5a5-9bf99d51d794",
   "metadata": {},
   "source": [
    "##### Deep Transfer Learning for Time Series\n",
    "\n",
    "Deep learning architectures have dramatically expanded the possibilities for transfer learning in time series analysis. Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM) networks can learn hierarchical representations of temporal patterns that often generalize across domains.\n",
    "\n",
    "A model initially trained on high-frequency financial data might extract features useful for analyzing medical time series, despite the apparent differences between these domains. The deep learning approach to transfer learning often involves freezing early layers of the network while retraining later layers on the target domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9543dbed-6281-4a9c-b22c-73168694333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q numpy pandas matplotlib\n",
    "!pip install -q scikit-learn tensorflow==2.18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e9e7d11-7fd1-41f1-9b63-7afa74c846b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0c6db2-0895-4e97-a70a-81ccd08dbc90",
   "metadata": {},
   "source": [
    "#### Basic Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc5c4ec7-f6cd-4df3-b5bf-0226c0b75f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input\n",
    "\n",
    "# Helper function to create time series sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        sequences.append(data[i:(i + seq_length)])\n",
    "    return np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edd99471-82b3-4453-8ee3-9c8bac20aee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare source domain data (e.g., energy consumption)\n",
    "source_data = pd.read_csv('../data/energy_consumption.csv')\n",
    "source_scaler = MinMaxScaler()\n",
    "source_scaled = source_scaler.fit_transform(source_data[['consumption']])\n",
    "source_sequences = create_sequences(source_scaled, seq_length=24)\n",
    "\n",
    "# Load and prepare target domain data (e.g., solar production)\n",
    "# solar_production.csv\n",
    "target_data = pd.read_csv('https://raw.githubusercontent.com/patricksheehan/All-Your-Battery-Are-Belong-To-Us/refs/heads/master/solar_production.csv')\n",
    "target_data.rename(columns={'v':'production'}, inplace=True)\n",
    "target_scaler = MinMaxScaler()\n",
    "target_scaled = target_scaler.fit_transform(target_data[['production']])\n",
    "target_sequences = create_sequences(target_scaled, seq_length=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c103499-c443-49b4-a2a7-6997b2a69392",
   "metadata": {},
   "source": [
    "#### Building a Base Model for Source Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87ece568-39b8-447c-b196-d4ccf20602ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1117 - val_loss: 0.0837\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0853 - val_loss: 0.0834\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0856 - val_loss: 0.0835\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0846 - val_loss: 0.0834\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0841 - val_loss: 0.0842\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0845 - val_loss: 0.0835\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0831 - val_loss: 0.0832\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0851 - val_loss: 0.0833\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0852 - val_loss: 0.0838\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0846 - val_loss: 0.0837\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0848 - val_loss: 0.0834\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0847 - val_loss: 0.0835\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0844 - val_loss: 0.0832\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0830 - val_loss: 0.0832\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0826 - val_loss: 0.0833\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0832 - val_loss: 0.0832\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0859 - val_loss: 0.0844\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0827 - val_loss: 0.0834\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0829 - val_loss: 0.0832\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0834 - val_loss: 0.0832\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0832 - val_loss: 0.0833\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0829 - val_loss: 0.0836\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0842 - val_loss: 0.0834\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0845 - val_loss: 0.0833\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0831 - val_loss: 0.0832\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0838 - val_loss: 0.0832\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0825 - val_loss: 0.0832\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0853 - val_loss: 0.0832\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0854 - val_loss: 0.0835\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0834 - val_loss: 0.0832\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0832 - val_loss: 0.0832\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0841 - val_loss: 0.0832\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0841 - val_loss: 0.0836\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0850 - val_loss: 0.0842\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0847 - val_loss: 0.0839\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0828 - val_loss: 0.0832\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0839 - val_loss: 0.0833\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0826 - val_loss: 0.0833\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0843 - val_loss: 0.0833\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0848 - val_loss: 0.0832\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0835 - val_loss: 0.0833\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0832 - val_loss: 0.0832\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0834 - val_loss: 0.0833\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0847 - val_loss: 0.0836\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0837 - val_loss: 0.0832\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0849 - val_loss: 0.0836\n",
      "Epoch 47/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0848 - val_loss: 0.0839\n",
      "Epoch 48/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0832 - val_loss: 0.0840\n",
      "Epoch 49/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0847 - val_loss: 0.0832\n",
      "Epoch 50/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0853 - val_loss: 0.0836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x281e380f590>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_base_model(sequence_length, n_features=1):\n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=(sequence_length, n_features), return_sequences=True, name='lstm_1'),\n",
    "        LSTM(32, name='lstm_2'),\n",
    "        Dense(16, activation='relu', name='dense_1'),\n",
    "        Dense(1, name='output')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Train base model on source domain\n",
    "source_model = create_base_model(24)\n",
    "source_model.fit(\n",
    "    source_sequences[:-1], \n",
    "    source_scaled[24:], \n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cec007-00d8-4f03-9457-e50a4534f165",
   "metadata": {},
   "source": [
    "#### Feature-based Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "061eb92e-4ec3-4c21-a9de-9d258e76efaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The layer sequential has never been called and thus has no defined input.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_feature_extractor\u001b[39m(base_model, layer_name=\u001b[33m'\u001b[39m\u001b[33mlstm_1\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Model(\n\u001b[32m      4\u001b[39m         inputs=base_model.input,\n\u001b[32m      5\u001b[39m         outputs=base_model.get_layer(layer_name).output\n\u001b[32m      6\u001b[39m     )\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m feature_extractor = \u001b[43mcreate_feature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mcreate_feature_extractor\u001b[39m\u001b[34m(base_model, layer_name)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_feature_extractor\u001b[39m(base_model, layer_name=\u001b[33m'\u001b[39m\u001b[33mlstm_1\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Model(\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m         inputs=\u001b[43mbase_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m,\n\u001b[32m      5\u001b[39m         outputs=base_model.get_layer(layer_name).output\n\u001b[32m      6\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\WORKSPACE\\GitHub\\shortthirdman\\Jupyter Notebooks\\TimeSeriesForecasting\\dev\\Lib\\site-packages\\keras\\src\\ops\\operation.py:276\u001b[39m, in \u001b[36mOperation.input\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    266\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    268\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Retrieves the input tensor(s) of a symbolic operation.\u001b[39;00m\n\u001b[32m    269\u001b[39m \n\u001b[32m    270\u001b[39m \u001b[33;03m    Only returns the tensor(s) corresponding to the *first time*\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    274\u001b[39m \u001b[33;03m        Input tensor or list of input tensors.\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_node_attribute_at_index\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_tensors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\WORKSPACE\\GitHub\\shortthirdman\\Jupyter Notebooks\\TimeSeriesForecasting\\dev\\Lib\\site-packages\\keras\\src\\ops\\operation.py:307\u001b[39m, in \u001b[36mOperation._get_node_attribute_at_index\u001b[39m\u001b[34m(self, node_index, attr, attr_name)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[32m    292\u001b[39m \n\u001b[32m    293\u001b[39m \u001b[33;03mThis is used to implement the properties:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    304\u001b[39m \u001b[33;03m    The operation's attribute `attr` at the node of index `node_index`.\u001b[39;00m\n\u001b[32m    305\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inbound_nodes:\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    308\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m has never been called \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    309\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mand thus has no defined \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    310\u001b[39m     )\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._inbound_nodes) > node_index:\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    313\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAsked to get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m at node \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    314\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, but the operation has only \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    315\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._inbound_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m inbound nodes.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    316\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: The layer sequential has never been called and thus has no defined input."
     ]
    }
   ],
   "source": [
    "# Extract features from intermediate layer\n",
    "def create_feature_extractor(base_model, layer_name='lstm_1'):\n",
    "    return Model(\n",
    "        inputs=base_model.input,\n",
    "        outputs=base_model.get_layer(layer_name).output\n",
    "    )\n",
    "\n",
    "feature_extractor = create_feature_extractor(source_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fc4f7a0-b1d3-488f-89eb-b1c05e751011",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_extractor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m     model.compile(optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m, loss=\u001b[33m'\u001b[39m\u001b[33mmse\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m transfer_model = create_transfer_model(\u001b[43mfeature_extractor\u001b[49m, \u001b[32m24\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'feature_extractor' is not defined"
     ]
    }
   ],
   "source": [
    "# Create new model using transferred features\n",
    "def create_transfer_model(feature_extractor, sequence_length):\n",
    "    inputs = Input(shape=(sequence_length, 1))\n",
    "    features = feature_extractor(inputs)\n",
    "    x = LSTM(16)(features)\n",
    "    outputs = Dense(1)(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "transfer_model = create_transfer_model(feature_extractor, 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244015cd-ba73-4f4a-b929-3fffa62d525b",
   "metadata": {},
   "source": [
    "#### Fine-tuning Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a7d2d1-ea09-4bac-98a2-ec2066cbe48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fine_tuning_model(base_model, trainable_layers=1):\n",
    "    # Freeze early layers\n",
    "    for layer in base_model.layers[:-trainable_layers]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    return base_model\n",
    "\n",
    "# Clone source model for fine-tuning\n",
    "fine_tune_model = tf.keras.models.clone_model(source_model)\n",
    "fine_tune_model.set_weights(source_model.get_weights())\n",
    "fine_tune_model = create_fine_tuning_model(fine_tune_model)\n",
    "\n",
    "# Fine-tune on target domain\n",
    "fine_tune_model.fit(\n",
    "    target_sequences[:-1],\n",
    "    target_scaled[24:],\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c1a501-9c03-4df3-834d-bb7683138c7c",
   "metadata": {},
   "source": [
    "#### Domain Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923f5223-5908-4ff7-8c5e-a46b41d709a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DomainAdapter:\n",
    "    def __init__(self, source_scaler, target_scaler):\n",
    "        self.source_scaler = source_scaler\n",
    "        self.target_scaler = target_scaler\n",
    "    \n",
    "    def adapt_sequence(self, sequence, from_domain='source', to_domain='target'):\n",
    "        if from_domain == 'source' and to_domain == 'target':\n",
    "            # Inverse transform to original scale\n",
    "            sequence_orig = self.source_scaler.inverse_transform(sequence)\n",
    "            # Transform to target scale\n",
    "            return self.target_scaler.transform(sequence_orig)\n",
    "        else:\n",
    "            sequence_orig = self.target_scaler.inverse_transform(sequence)\n",
    "            return self.source_scaler.transform(sequence_orig)\n",
    "\n",
    "# Create and use domain adapter\n",
    "adapter = DomainAdapter(source_scaler, target_scaler)\n",
    "adapted_sequences = adapter.adapt_sequence(source_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4537830-afee-412f-b785-3765607d9dfe",
   "metadata": {},
   "source": [
    "#### Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ed7d78-223e-49c1-bb0c-3ffca5dcdf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models, test_sequences, test_targets):\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        predictions = model.predict(test_sequences)\n",
    "        mse = tf.keras.losses.MSE(test_targets, predictions)\n",
    "        mae = tf.keras.losses.MAE(test_targets, predictions)\n",
    "        results[name] = {'MSE': float(mse), 'MAE': float(mae)}\n",
    "    return pd.DataFrame(results).T\n",
    "\n",
    "# Compare different approaches\n",
    "models = {\n",
    "    'Base Model': source_model,\n",
    "    'Transfer Learning': transfer_model,\n",
    "    'Fine-tuned': fine_tune_model\n",
    "}\n",
    "\n",
    "results = evaluate_models(\n",
    "    models,\n",
    "    target_sequences[-100:],\n",
    "    target_scaled[-100:]\n",
    ")\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421f6842-d74a-467c-ba5d-c1c34aa27d09",
   "metadata": {},
   "source": [
    "#### Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3671ef-8618-4191-9776-b109a217990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_predictions(models, test_sequences, true_values, scaler):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Plot true values\n",
    "    plt.plot(scaler.inverse_transform(true_values), \n",
    "             label='Actual', linewidth=2)\n",
    "    \n",
    "    # Plot predictions from each model\n",
    "    for name, model in models.items():\n",
    "        predictions = model.predict(test_sequences)\n",
    "        plt.plot(scaler.inverse_transform(predictions), \n",
    "                label=f'{name} Predictions', linestyle='--')\n",
    "    \n",
    "    plt.title('Model Predictions Comparison')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize results\n",
    "plot_predictions(\n",
    "    models,\n",
    "    target_sequences[-100:],\n",
    "    target_scaled[-100:],\n",
    "    target_scaler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51fdb0c-3aea-46d7-b554-92ca779f20c8",
   "metadata": {},
   "source": [
    "#### Best Practices and Implementation Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bade836-8361-4f0b-b427-8b2580d6a2ca",
   "metadata": {},
   "source": [
    "- First, source and target domains should share meaningful similarities in their temporal patterns or underlying generative processes.\n",
    "- Second, the transfer learning approach should account for differences in scale, sampling frequency, and noise levels between domains.\n",
    "- Third, validation strategies must carefully assess whether the transferred knowledge improves or potentially degrades performance in the target domain."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
