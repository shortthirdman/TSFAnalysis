{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2050ce42-aa68-433f-a0ae-278c0e74512f",
   "metadata": {},
   "source": [
    "### Time Series Analysis with Kats\n",
    "\n",
    "> [A Python Toolkit by Meta](https://wire.insiderfinance.io/time-series-analysis-with-kats-a-python-toolkit-by-meta-42de2934971d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032a064d-ab86-41a9-ae8b-359ade0692e5",
   "metadata": {},
   "source": [
    "Kats stands for \"Kit to Analyze Time Series\" and it's exactly what it sounds like ‚Äî a one-stop shop for tackling time series data: a open-source time series analysis toolkit from *Meta*.\n",
    "\n",
    "Kats wraps up tools for forecasting, detection, feature extraction, and even simulation into a package that's easy to pick up, whether you're a newbie or a seasoned coder. Meta built it for real-world problems, but they‚Äôve kept it approachable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bf5b0c-f63b-46db-9504-6b001396b29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U kats pandas matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579f029a-9863-45b5-a387-d5e20372b214",
   "metadata": {},
   "source": [
    "#### Forecasting: Guessing What‚Äôs Next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991d3f03-3416-4815-a725-8460e71aa627",
   "metadata": {},
   "source": [
    "Forecasting is all about peering into the future ‚Äî like figuring out next quarter‚Äôs revenue or tomorrow‚Äôs weather. Kats pulls in some heavy hitters to make this happen:\n",
    "\n",
    "- **ARIMA:** The go-to for spotting trends and seasonal quirks.\n",
    "- **Prophet:** Meta's own creation, awesome for messy data or holiday spikes.\n",
    "- **Holt-Winters:** A champ at handling repeating patterns.\n",
    "- **VAR:** Handy when you‚Äôve got multiple variables playing off each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771ec8ed-9efc-4d2c-9a47-88f499560ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from kats.models.prophet import ProphetModel, ProphetParams\n",
    "from kats.utils.time_series import TimeSeriesData\n",
    "\n",
    "# Load dataset\n",
    "try:\n",
    "    sales = pd.read_csv(\"../../data/daily_sales.csv\")\n",
    "\n",
    "    # Ensure dataset contains required columns\n",
    "    if \"time\" not in sales.columns or \"value\" not in sales.columns:\n",
    "        raise ValueError(\"Dataset must contain 'time' and 'value' columns.\")\n",
    "\n",
    "    sales[\"time\"] = pd.to_datetime(sales[\"time\"])  # Convert time column to datetime\n",
    "\n",
    "    # Convert to Kats TimeSeriesData format\n",
    "    ts_data = TimeSeriesData(sales)\n",
    "\n",
    "    # Set up Prophet with a seasonal component\n",
    "    params = ProphetParams(seasonality_mode=\"multiplicative\")\n",
    "    model = ProphetModel(ts_data, params)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit()\n",
    "\n",
    "    # Forecast the next 30 days\n",
    "    future = model.predict(steps=30)\n",
    "    print(\"Future Forecast:\")\n",
    "    print(future.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The file 'daily_sales.csv' was not found. Please check the file path.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bd58f3-ed98-49d7-a1e2-78ed663ff5bf",
   "metadata": {},
   "source": [
    "#### Detection: Finding the Weird Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea9c482-ad78-4501-907e-14a31750b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from kats.detectors.outlier import OutlierDetector\n",
    "from kats.utils.time_series import TimeSeriesData\n",
    "\n",
    "# Load up some traffic numbers\n",
    "try:\n",
    "    traffic = pd.read_csv(\"../../data/web_traffic.csv\")\n",
    "    traffic[\"time\"] = pd.to_datetime(traffic[\"time\"])\n",
    "    \n",
    "    # Ensure the dataset has required columns\n",
    "    if \"value\" not in traffic.columns:\n",
    "        raise ValueError(\"Dataset must contain a 'value' column for analysis.\")\n",
    "\n",
    "    # Convert to Kats TimeSeriesData format\n",
    "    ts_data = TimeSeriesData(traffic)\n",
    "\n",
    "    # Fire up the detector\n",
    "    detector = OutlierDetector(ts_data)\n",
    "    detector.detector()\n",
    "    weird_spots = detector.outliers  # List of timestamps where anomalies are detected\n",
    "    \n",
    "    print(\"Strange days:\", weird_spots)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The file 'web_traffic.csv' was not found. Please check the file path.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48437342-18e4-449e-8f50-ead9076d5f8f",
   "metadata": {},
   "source": [
    "#### Feature Extraction: Digging Out the Good Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90763423-3374-43e6-a178-448a2f0cb05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from kats.tsfeatures.tsfeatures import TsFeatures\n",
    "from kats.utils.time_series import TimeSeriesData\n",
    "\n",
    "# Load sensor data\n",
    "try:\n",
    "    sensors = pd.read_csv(\"../../data/sensor_logs.csv\")  # Ensure you have this file\n",
    "    sensors[\"time\"] = pd.to_datetime(sensors[\"time\"])  # Convert to datetime\n",
    "    sensors.set_index(\"time\", inplace=True)  # Set time as index\n",
    "\n",
    "    # Ensure the dataset has numerical values\n",
    "    sensor_columns = [col for col in sensors.columns if sensors[col].dtype in ['float64', 'int64']]\n",
    "    \n",
    "    if not sensor_columns:\n",
    "        raise ValueError(\"No numerical sensor data found. Ensure data contains valid values.\")\n",
    "\n",
    "    # Extract features using Kats\n",
    "    extractor = TsFeatures()\n",
    "    ts_data = TimeSeriesData(sensors.reset_index())\n",
    "    insights = extractor.transform(ts_data)\n",
    "\n",
    "    # Print Extracted Features\n",
    "    print(\"\\nüìä Extracted Time-Series Features:\")\n",
    "    print(insights)\n",
    "\n",
    "    # Visualization: Plot sensor data trends\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for col in sensor_columns:\n",
    "        plt.plot(sensors.index, sensors[col], label=col)\n",
    "\n",
    "    plt.title(\"Sensor Data Trends Over Time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Sensor Readings\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.show()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: The file 'sensor_logs.csv' was not found. Please check the file path.\")\n",
    "except ValueError as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Unexpected Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbef897-6952-4d4e-a0a5-20f3910ac4af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
