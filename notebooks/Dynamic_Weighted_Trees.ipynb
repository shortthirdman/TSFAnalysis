{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9d0f040-3b8f-43a2-b67f-91bdedb869c8",
   "metadata": {},
   "source": [
    "### [Enhancing Time Series Forecasting with Dynamic Weighted Trees](https://medium.com/data-science-collective/enhancing-time-series-forecasting-with-dynamic-weighted-trees-8dad9aeae112)\n",
    "\n",
    "> A Practical, High-Performance, and Interpretable Decision Tree Approach Incorporating Autoregressive Lags, Seasonal Dynamics, and Recency-Driven Weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87709b6a-9330-4734-be66-b18fd0e1cb3e",
   "metadata": {},
   "source": [
    "#### A Weighted Tree Approach for Time Series Forecasting\n",
    "\n",
    "Time series forecasting often relies on autoregressive (AR) principles, which assume linear relationships among lagged observations.\n",
    "\n",
    "Time series forecasting involves predicting future values based on previously observed data points. Capturing trends, seasonality, and noise are crucial for accurate forecasts. Decision tree-based models such as Random Forests and Gradient Boosted Trees (e.g., XGBoost, LightGBM) have shown strong performance due to their ability to model non-linear relationships and handle high-dimensional data. However, these models are not inherently designed for temporal data and often treat all observations equally.\n",
    "\n",
    "The proposed Weighted Tree Approach introduces a temporal bias into tree-based forecasting models by assigning weights to observations based on their temporal proximity or relevance, thereby enabling the model to emphasize recent or more contextually relevant data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bc5b83-993a-44f9-8e68-8cf04ab9a179",
   "metadata": {},
   "source": [
    "#### **2. Methodology**\n",
    "\n",
    "##### 2.1 Base Model: Tree-Based Regressors\n",
    "The core forecasting model is built using ensemble tree algorithms:\n",
    "- **Gradient Boosted Trees** for their predictive accuracy.\n",
    "- **Random Forests** for robustness and interpretability.\n",
    "\n",
    "##### 2.2 Time-Aware Feature Engineering\n",
    "Key features are extracted from the time series, including:\n",
    "- Lagged variables (e.g., \\( y_{t-1}, y_{t-2} \\))\n",
    "- Rolling statistics (mean, variance)\n",
    "- Calendar features (day of week, month, etc.)\n",
    "- Seasonal decomposition components\n",
    "\n",
    "##### 2.3 Temporal Weighting Mechanism\n",
    "The novel contribution lies in incorporating **weights** based on:\n",
    "- **Time decay**: Older observations receive lower weights using functions like exponential decay \\( w_t = e^{-\\lambda (T - t)} \\)\n",
    "- **Contextual importance**: Weighting based on seasonality or event impact\n",
    "- **Anomaly-aware weighting**: Reducing the influence of detected outliers\n",
    "\n",
    "These weights are fed into the training process, influencing either the loss function or the sampling process of trees.\n",
    "\n",
    "##### 2.4 Forecast Generation\n",
    "The model generates point forecasts and can be extended to produce prediction intervals using techniques like quantile regression forests or bootstrapped ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caec4c8f-eb3a-4851-a267-00080ad19c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q numpy pandas matplotlib scikit-learn statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc4ed3d2-2ef7-46ef-be30-c5a497b77f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "import re\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import statsmodels for OLS estimation\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# ----------------------\n",
    "# Suppress warnings (if any)\n",
    "# ----------------------\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bfdf39e-192e-4bfb-aa57-eaa16c1f4196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== Helper Functions for Tree Model =========\n",
    "\n",
    "def add_cycle_features(df, date_col=\"DATE\"):\n",
    "    \"\"\"\n",
    "    Adds cyclical features based on day-of-week.\n",
    "    \"\"\"\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    df['dayofweek'] = df[date_col].dt.dayofweek  # Monday=0, Sunday=6\n",
    "    df['sin_dow'] = np.sin(2 * np.pi * df['dayofweek'] / 7)\n",
    "    df['cos_dow'] = np.cos(2 * np.pi * df['dayofweek'] / 7)\n",
    "    return df\n",
    "\n",
    "def add_ma_feature(series, window=3):\n",
    "    \"\"\"\n",
    "    Computes a moving-average feature over a given window.\n",
    "    \"\"\"\n",
    "    return series.rolling(window=window, min_periods=1).mean()\n",
    "\n",
    "def construct_lagged_dataset(df, target_col, L, decay_rate, date_col=\"DATE\"):\n",
    "    \"\"\"\n",
    "    For each time t (>= L) build feature vector composed of:\n",
    "      - L lagged values (most recent first)\n",
    "      - Current cyclical features (sin_dow, cos_dow)\n",
    "      - MA feature: average of previous 3 observations\n",
    "    Also computes an exponential decay weight.\n",
    "    \"\"\"\n",
    "    df = df.copy().reset_index(drop=True)\n",
    "    n = len(df)\n",
    "    X, y, weights, dates = [], [], [], []\n",
    "    T_max = n - 1\n",
    "    for t in range(L, n):\n",
    "        lag_feats = df[target_col].iloc[t-L:t].values[::-1].tolist()\n",
    "        sin_dow = df.loc[t, 'sin_dow']\n",
    "        cos_dow = df.loc[t, 'cos_dow']\n",
    "        ma_feat = df[target_col].iloc[max(t-3, 0):t].mean()\n",
    "        feat = lag_feats + [sin_dow, cos_dow, ma_feat]\n",
    "        X.append(feat)\n",
    "        y.append(df.loc[t, target_col])\n",
    "        dates.append(df.loc[t, date_col])\n",
    "        weight = math.exp(-decay_rate * (T_max - t))\n",
    "        weights.append(weight)\n",
    "    return np.array(X), np.array(y), np.array(weights), pd.to_datetime(dates)\n",
    "\n",
    "def forecast_recursive(model, seed_window, seed_date, forecast_horizon, L, exog_df=None):\n",
    "    \"\"\"\n",
    "    Given a fitted regression model (OLS or tree-based) and a seed window (most recent L observations),\n",
    "    forecast recursively for forecast_horizon days.\n",
    "    If exogenous features for future dates are provided in exog_df, they are used;\n",
    "    otherwise, cycle features are computed from the forecast date.\n",
    "    \n",
    "    NOTE for tree-based models: the predicted feature vector must have the same dimension as during training.\n",
    "    \"\"\"\n",
    "    forecasts = []\n",
    "    current_window = list(seed_window)\n",
    "    current_date = seed_date\n",
    "    for h in range(forecast_horizon):\n",
    "        next_date = current_date + pd.Timedelta(days=1)\n",
    "        lag_feats = current_window[-L:][::-1]\n",
    "        if exog_df is not None:\n",
    "            cyc_vals = exog_df.loc[next_date]\n",
    "            cyc_array = np.array([cyc_vals['sin_dow'], cyc_vals['cos_dow']])\n",
    "        else:\n",
    "            dow = next_date.dayofweek\n",
    "            cyc_array = np.array([np.sin(2 * np.pi * dow / 7), np.cos(2 * np.pi * dow / 7)])\n",
    "        ma_feat = np.mean(current_window[-3:]) if len(current_window) >= 3 else np.mean(current_window)\n",
    "        # Concatenate lag features, cycle features, and MA feature. Total length = L + 3.\n",
    "        feat = np.concatenate([np.array(lag_feats), cyc_array, [ma_feat]])\n",
    "        # For tree models, do not add constant.\n",
    "        X_pred = feat.reshape(1, -1)\n",
    "        y_hat = model.predict(X_pred)[0]\n",
    "        forecasts.append(y_hat)\n",
    "        current_window.append(y_hat)\n",
    "        current_date = next_date\n",
    "    return forecasts\n",
    "\n",
    "def rolling_forecast_evaluation(model, df, target_col, L, forecast_horizon, decay_rate, start_idx):\n",
    "    \"\"\"\n",
    "    Rolling-origin evaluation for the tree-based forecasting model.\n",
    "    Returns MAPE (%) computed over all rolling origins.\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    n = len(df)\n",
    "    for i in range(start_idx, n - forecast_horizon):\n",
    "        if i - L < 0:\n",
    "            continue\n",
    "        seed_window = df[target_col].iloc[i-L:i].values\n",
    "        seed_date = df.iloc[i-1]['DATE']\n",
    "        preds = forecast_recursive(model, seed_window, seed_date, forecast_horizon, L)\n",
    "        pred_avg = np.mean(preds)\n",
    "        actual_avg = df[target_col].iloc[i:i+forecast_horizon].mean()\n",
    "        if actual_avg == 0:\n",
    "            continue\n",
    "        errors.append(abs((actual_avg - pred_avg) / actual_avg))\n",
    "    return np.mean(errors)*100 if errors else None\n",
    "\n",
    "# ======== Additional Helper Functions: AR/ARMA with OLS =========\n",
    "\n",
    "def rolling_forecast_evaluation_ar_ols(series, exog, p, forecast_horizon, start_idx):\n",
    "    \"\"\"\n",
    "    Rolling-origin forecast evaluation for an AR(p) model using OLS.\n",
    "    Predictors: constant, p lagged values, and exogenous cycle features.\n",
    "    'series' is a pandas Series of the target.\n",
    "    'exog' is a DataFrame (with same index as series) containing cycle features (e.g., sin_dow, cos_dow).\n",
    "    Returns MAPE (%) over all rolling origins.\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    n = len(series)\n",
    "    for i in range(start_idx, n - forecast_horizon):\n",
    "        X_train, y_train = [], []\n",
    "        for t in range(p, i):\n",
    "            lags = series.iloc[t-p:t].values    # shape: (p,)\n",
    "            cyc = exog.iloc[t].values             # shape: (2,)\n",
    "            X_train.append(np.concatenate([lags, cyc]))  # total length = p + 2\n",
    "            y_train.append(series.iloc[t])\n",
    "        if len(X_train) == 0:\n",
    "            continue\n",
    "        X_train = np.array(X_train)\n",
    "        y_train = np.array(y_train)\n",
    "        # Manually add constant column\n",
    "        X_train_const = np.column_stack((np.ones(len(X_train)), X_train))\n",
    "        model = sm.OLS(y_train, X_train_const).fit()\n",
    "        seed_window = series.iloc[i-p:i].values.copy().tolist()\n",
    "        current_index = i\n",
    "        preds = []\n",
    "        for k in range(forecast_horizon):\n",
    "            cyc_forecast = exog.iloc[current_index].values  # shape: (2,)\n",
    "            x_row = np.concatenate([np.array(seed_window[-p:]), cyc_forecast])  # length = p + 2\n",
    "            X_pred = np.column_stack((np.ones(1), x_row.reshape(1, -1)))  # shape: (1, p+3)\n",
    "            y_hat = model.predict(X_pred)[0]\n",
    "            preds.append(y_hat)\n",
    "            seed_window.append(y_hat)\n",
    "            current_index += 1\n",
    "            if current_index >= n:\n",
    "                break\n",
    "        if len(preds) < forecast_horizon:\n",
    "            continue\n",
    "        pred_avg = np.mean(preds)\n",
    "        actual_avg = series.iloc[i:i+forecast_horizon].mean()\n",
    "        if actual_avg == 0:\n",
    "            continue\n",
    "        errors.append(abs((actual_avg - pred_avg) / actual_avg))\n",
    "    return np.mean(errors)*100 if errors else None\n",
    "\n",
    "def rolling_forecast_evaluation_arma_ols(series, exog, forecast_horizon, start_idx):\n",
    "    \"\"\"\n",
    "    Rolling-origin forecast evaluation for a simplified ARMA(1,1) model estimated via OLS.\n",
    "    Predictors: constant, lag1 (y[t-1]), lagged error (approx. y[t-1] - y[t-2]),\n",
    "                and exogenous cycle features.\n",
    "    Returns MAPE (%) over all rolling origins.\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    n = len(series)\n",
    "    for i in range(max(start_idx, 2), n - forecast_horizon):\n",
    "        X_train, y_train = [], []\n",
    "        for t in range(2, i):\n",
    "            lag1 = series.iloc[t-1]\n",
    "            lag_err = series.iloc[t-1] - series.iloc[t-2]\n",
    "            cyc = exog.iloc[t].values\n",
    "            X_train.append(np.concatenate([[lag1, lag_err], cyc]))  # length = 2+2 = 4\n",
    "            y_train.append(series.iloc[t])\n",
    "        if len(X_train) == 0:\n",
    "            continue\n",
    "        X_train = np.array(X_train)\n",
    "        y_train = np.array(y_train)\n",
    "        X_train_const = np.column_stack((np.ones(len(X_train)), X_train))\n",
    "        model = sm.OLS(y_train, X_train_const).fit()\n",
    "        seed_y = series.iloc[i]\n",
    "        seed_err = series.iloc[i] - series.iloc[i-1]\n",
    "        preds = []\n",
    "        current_index = i+1\n",
    "        for k in range(forecast_horizon):\n",
    "            cyc_forecast = exog.iloc[current_index].values\n",
    "            x_row = np.concatenate([[seed_y, seed_err], cyc_forecast])  # length = 4\n",
    "            X_pred = np.column_stack((np.ones(1), x_row.reshape(1, -1)))   # shape: (1, 5)\n",
    "            y_hat = model.predict(X_pred)[0]\n",
    "            preds.append(y_hat)\n",
    "            new_err = y_hat - seed_y\n",
    "            seed_y = y_hat\n",
    "            seed_err = new_err\n",
    "            current_index += 1\n",
    "            if current_index >= n:\n",
    "                break\n",
    "        if len(preds) < forecast_horizon:\n",
    "            continue\n",
    "        pred_avg = np.mean(preds)\n",
    "        actual_avg = series.iloc[i+1:i+1+forecast_horizon].mean()\n",
    "        if actual_avg == 0:\n",
    "            continue\n",
    "        errors.append(abs((actual_avg - pred_avg) / actual_avg))\n",
    "    return np.mean(errors)*100 if errors else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40d100cd-dc4b-4eb5-a4f1-0518ac7d2e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total observations: 397\n",
      "Training observations: 317\n",
      "Test observations: 80\n",
      "\n",
      "[Tree Model] Forecast Horizon: 3 days\n",
      "  Candidate Lag L=3: Validation MAPE = 1.91%\n",
      "  Candidate Lag L=5: Validation MAPE = 2.23%\n",
      "  Candidate Lag L=7: Validation MAPE = 1.86%\n",
      "  Candidate Lag L=9: Validation MAPE = 2.08%\n",
      "--> Best Lag for horizon 3 days: L = 7 with Validation MAPE = 1.86%\n",
      "Decision Tree Rules:\n",
      "|--- lag_6 <= 94.84\n",
      "|   |--- lag_6 <= 81.44\n",
      "|   |   |--- lag_6 <= 71.13\n",
      "|   |   |   |--- lag_6 <= 62.54\n",
      "|   |   |   |   |--- lag_6 <= 58.05\n",
      "|   |   |   |   |   |--- value: [57.81]\n",
      "|   |   |   |   |--- lag_6 >  58.05\n",
      "|   |   |   |   |   |--- value: [63.11]\n",
      "|   |   |   |--- lag_6 >  62.54\n",
      "|   |   |   |   |--- lag_1 <= 67.83\n",
      "|   |   |   |   |   |--- value: [66.69]\n",
      "|   |   |   |   |--- lag_1 >  67.83\n",
      "|   |   |   |   |   |--- value: [71.22]\n",
      "|   |   |--- lag_6 >  71.13\n",
      "|   |   |   |--- lag_1 <= 71.79\n",
      "|   |   |   |   |--- lag_6 <= 71.99\n",
      "|   |   |   |   |   |--- value: [77.68]\n",
      "|   |   |   |   |--- lag_6 >  71.99\n",
      "|   |   |   |   |   |--- value: [70.03]\n",
      "|   |   |   |--- lag_1 >  71.79\n",
      "|   |   |   |   |--- lag_5 <= 71.16\n",
      "|   |   |   |   |   |--- value: [75.19]\n",
      "|   |   |   |   |--- lag_5 >  71.16\n",
      "|   |   |   |   |   |--- value: [80.45]\n",
      "|   |--- lag_6 >  81.44\n",
      "|   |   |--- lag_6 <= 90.78\n",
      "|   |   |   |--- lag_1 <= 78.91\n",
      "|   |   |   |   |--- lag_1 <= 68.53\n",
      "|   |   |   |   |   |--- value: [73.15]\n",
      "|   |   |   |   |--- lag_1 >  68.53\n",
      "|   |   |   |   |   |--- value: [78.83]\n",
      "|   |   |   |--- lag_1 >  78.91\n",
      "|   |   |   |   |--- lag_6 <= 83.21\n",
      "|   |   |   |   |   |--- value: [85.04]\n",
      "|   |   |   |   |--- lag_6 >  83.21\n",
      "|   |   |   |   |   |--- value: [89.09]\n",
      "|   |   |--- lag_6 >  90.78\n",
      "|   |   |   |--- lag_1 <= 81.92\n",
      "|   |   |   |   |--- lag_1 <= 78.01\n",
      "|   |   |   |   |   |--- value: [82.53]\n",
      "|   |   |   |   |--- lag_1 >  78.01\n",
      "|   |   |   |   |   |--- value: [86.89]\n",
      "|   |   |   |--- lag_1 >  81.92\n",
      "|   |   |   |   |--- ma_feat <= 91.12\n",
      "|   |   |   |   |   |--- value: [97.69]\n",
      "|   |   |   |   |--- ma_feat >  91.12\n",
      "|   |   |   |   |   |--- value: [91.92]\n",
      "|--- lag_6 >  94.84\n",
      "|   |--- lag_5 <= 94.43\n",
      "|   |   |--- lag_2 <= 78.04\n",
      "|   |   |   |--- lag_2 <= 75.26\n",
      "|   |   |   |   |--- value: [88.45]\n",
      "|   |   |   |--- lag_2 >  75.26\n",
      "|   |   |   |   |--- value: [85.96]\n",
      "|   |   |--- lag_2 >  78.04\n",
      "|   |   |   |--- lag_5 <= 92.87\n",
      "|   |   |   |   |--- lag_7 <= 108.67\n",
      "|   |   |   |   |   |--- value: [96.73]\n",
      "|   |   |   |   |--- lag_7 >  108.67\n",
      "|   |   |   |   |   |--- value: [99.68]\n",
      "|   |   |   |--- lag_5 >  92.87\n",
      "|   |   |   |   |--- lag_4 <= 87.81\n",
      "|   |   |   |   |   |--- value: [103.36]\n",
      "|   |   |   |   |--- lag_4 >  87.81\n",
      "|   |   |   |   |   |--- value: [99.17]\n",
      "|   |--- lag_5 >  94.43\n",
      "|   |   |--- lag_2 <= 88.39\n",
      "|   |   |   |--- lag_1 <= 89.32\n",
      "|   |   |   |   |--- sin_dow <= 0.22\n",
      "|   |   |   |   |   |--- value: [90.78]\n",
      "|   |   |   |   |--- sin_dow >  0.22\n",
      "|   |   |   |   |   |--- value: [97.45]\n",
      "|   |   |   |--- lag_1 >  89.32\n",
      "|   |   |   |   |--- lag_1 <= 98.37\n",
      "|   |   |   |   |   |--- value: [102.77]\n",
      "|   |   |   |   |--- lag_1 >  98.37\n",
      "|   |   |   |   |   |--- value: [108.63]\n",
      "|   |   |--- lag_2 >  88.39\n",
      "|   |   |   |--- lag_1 <= 105.10\n",
      "|   |   |   |   |--- cos_dow <= 0.20\n",
      "|   |   |   |   |   |--- value: [110.00]\n",
      "|   |   |   |   |--- cos_dow >  0.20\n",
      "|   |   |   |   |   |--- value: [105.12]\n",
      "|   |   |   |--- lag_1 >  105.10\n",
      "|   |   |   |   |--- lag_5 <= 103.64\n",
      "|   |   |   |   |   |--- value: [109.77]\n",
      "|   |   |   |   |--- lag_5 >  103.64\n",
      "|   |   |   |   |   |--- value: [115.92]\n",
      "\n",
      "[Tree Model] Test MAPE for horizon 3 days: 3.32%\n",
      "\n",
      "[Tree Model] Forecast Horizon: 5 days\n",
      "  Candidate Lag L=3: Validation MAPE = 2.31%\n",
      "  Candidate Lag L=5: Validation MAPE = 1.92%\n",
      "  Candidate Lag L=7: Validation MAPE = 1.65%\n",
      "  Candidate Lag L=9: Validation MAPE = 2.35%\n",
      "--> Best Lag for horizon 5 days: L = 7 with Validation MAPE = 1.65%\n",
      "Decision Tree Rules:\n",
      "|--- lag_6 <= 94.84\n",
      "|   |--- lag_6 <= 81.44\n",
      "|   |   |--- lag_6 <= 71.13\n",
      "|   |   |   |--- lag_6 <= 62.54\n",
      "|   |   |   |   |--- lag_6 <= 58.05\n",
      "|   |   |   |   |   |--- value: [57.81]\n",
      "|   |   |   |   |--- lag_6 >  58.05\n",
      "|   |   |   |   |   |--- value: [63.11]\n",
      "|   |   |   |--- lag_6 >  62.54\n",
      "|   |   |   |   |--- lag_1 <= 67.83\n",
      "|   |   |   |   |   |--- value: [66.69]\n",
      "|   |   |   |   |--- lag_1 >  67.83\n",
      "|   |   |   |   |   |--- value: [71.22]\n",
      "|   |   |--- lag_6 >  71.13\n",
      "|   |   |   |--- lag_1 <= 71.79\n",
      "|   |   |   |   |--- lag_6 <= 71.99\n",
      "|   |   |   |   |   |--- value: [77.68]\n",
      "|   |   |   |   |--- lag_6 >  71.99\n",
      "|   |   |   |   |   |--- value: [70.03]\n",
      "|   |   |   |--- lag_1 >  71.79\n",
      "|   |   |   |   |--- lag_5 <= 71.16\n",
      "|   |   |   |   |   |--- value: [75.19]\n",
      "|   |   |   |   |--- lag_5 >  71.16\n",
      "|   |   |   |   |   |--- value: [80.45]\n",
      "|   |--- lag_6 >  81.44\n",
      "|   |   |--- lag_6 <= 90.78\n",
      "|   |   |   |--- lag_1 <= 78.91\n",
      "|   |   |   |   |--- lag_1 <= 68.53\n",
      "|   |   |   |   |   |--- value: [73.15]\n",
      "|   |   |   |   |--- lag_1 >  68.53\n",
      "|   |   |   |   |   |--- value: [78.83]\n",
      "|   |   |   |--- lag_1 >  78.91\n",
      "|   |   |   |   |--- lag_6 <= 83.21\n",
      "|   |   |   |   |   |--- value: [85.04]\n",
      "|   |   |   |   |--- lag_6 >  83.21\n",
      "|   |   |   |   |   |--- value: [89.09]\n",
      "|   |   |--- lag_6 >  90.78\n",
      "|   |   |   |--- lag_1 <= 81.92\n",
      "|   |   |   |   |--- lag_1 <= 78.01\n",
      "|   |   |   |   |   |--- value: [82.53]\n",
      "|   |   |   |   |--- lag_1 >  78.01\n",
      "|   |   |   |   |   |--- value: [86.89]\n",
      "|   |   |   |--- lag_1 >  81.92\n",
      "|   |   |   |   |--- ma_feat <= 91.12\n",
      "|   |   |   |   |   |--- value: [97.69]\n",
      "|   |   |   |   |--- ma_feat >  91.12\n",
      "|   |   |   |   |   |--- value: [91.92]\n",
      "|--- lag_6 >  94.84\n",
      "|   |--- lag_5 <= 94.43\n",
      "|   |   |--- lag_2 <= 78.04\n",
      "|   |   |   |--- lag_2 <= 75.26\n",
      "|   |   |   |   |--- value: [88.45]\n",
      "|   |   |   |--- lag_2 >  75.26\n",
      "|   |   |   |   |--- value: [85.96]\n",
      "|   |   |--- lag_2 >  78.04\n",
      "|   |   |   |--- lag_5 <= 92.87\n",
      "|   |   |   |   |--- lag_7 <= 108.67\n",
      "|   |   |   |   |   |--- value: [96.73]\n",
      "|   |   |   |   |--- lag_7 >  108.67\n",
      "|   |   |   |   |   |--- value: [99.68]\n",
      "|   |   |   |--- lag_5 >  92.87\n",
      "|   |   |   |   |--- lag_4 <= 87.81\n",
      "|   |   |   |   |   |--- value: [103.36]\n",
      "|   |   |   |   |--- lag_4 >  87.81\n",
      "|   |   |   |   |   |--- value: [99.17]\n",
      "|   |--- lag_5 >  94.43\n",
      "|   |   |--- lag_2 <= 88.39\n",
      "|   |   |   |--- lag_1 <= 89.32\n",
      "|   |   |   |   |--- sin_dow <= 0.22\n",
      "|   |   |   |   |   |--- value: [90.78]\n",
      "|   |   |   |   |--- sin_dow >  0.22\n",
      "|   |   |   |   |   |--- value: [97.45]\n",
      "|   |   |   |--- lag_1 >  89.32\n",
      "|   |   |   |   |--- lag_1 <= 98.37\n",
      "|   |   |   |   |   |--- value: [102.77]\n",
      "|   |   |   |   |--- lag_1 >  98.37\n",
      "|   |   |   |   |   |--- value: [108.63]\n",
      "|   |   |--- lag_2 >  88.39\n",
      "|   |   |   |--- lag_1 <= 105.10\n",
      "|   |   |   |   |--- cos_dow <= 0.20\n",
      "|   |   |   |   |   |--- value: [110.00]\n",
      "|   |   |   |   |--- cos_dow >  0.20\n",
      "|   |   |   |   |   |--- value: [105.12]\n",
      "|   |   |   |--- lag_1 >  105.10\n",
      "|   |   |   |   |--- lag_5 <= 103.64\n",
      "|   |   |   |   |   |--- value: [109.77]\n",
      "|   |   |   |   |--- lag_5 >  103.64\n",
      "|   |   |   |   |   |--- value: [115.92]\n",
      "\n",
      "[Tree Model] Test MAPE for horizon 5 days: 2.74%\n",
      "\n",
      "[Tree Model] Forecast Horizon: 7 days\n",
      "  Candidate Lag L=3: Validation MAPE = 2.20%\n",
      "  Candidate Lag L=5: Validation MAPE = 1.48%\n",
      "  Candidate Lag L=7: Validation MAPE = 1.48%\n",
      "  Candidate Lag L=9: Validation MAPE = 2.44%\n",
      "--> Best Lag for horizon 7 days: L = 7 with Validation MAPE = 1.48%\n",
      "Decision Tree Rules:\n",
      "|--- lag_6 <= 94.84\n",
      "|   |--- lag_6 <= 81.44\n",
      "|   |   |--- lag_6 <= 71.13\n",
      "|   |   |   |--- lag_6 <= 62.54\n",
      "|   |   |   |   |--- lag_6 <= 58.05\n",
      "|   |   |   |   |   |--- value: [57.81]\n",
      "|   |   |   |   |--- lag_6 >  58.05\n",
      "|   |   |   |   |   |--- value: [63.11]\n",
      "|   |   |   |--- lag_6 >  62.54\n",
      "|   |   |   |   |--- lag_1 <= 67.83\n",
      "|   |   |   |   |   |--- value: [66.69]\n",
      "|   |   |   |   |--- lag_1 >  67.83\n",
      "|   |   |   |   |   |--- value: [71.22]\n",
      "|   |   |--- lag_6 >  71.13\n",
      "|   |   |   |--- lag_1 <= 71.79\n",
      "|   |   |   |   |--- lag_6 <= 71.99\n",
      "|   |   |   |   |   |--- value: [77.68]\n",
      "|   |   |   |   |--- lag_6 >  71.99\n",
      "|   |   |   |   |   |--- value: [70.03]\n",
      "|   |   |   |--- lag_1 >  71.79\n",
      "|   |   |   |   |--- lag_5 <= 71.16\n",
      "|   |   |   |   |   |--- value: [75.19]\n",
      "|   |   |   |   |--- lag_5 >  71.16\n",
      "|   |   |   |   |   |--- value: [80.45]\n",
      "|   |--- lag_6 >  81.44\n",
      "|   |   |--- lag_6 <= 90.78\n",
      "|   |   |   |--- lag_1 <= 78.91\n",
      "|   |   |   |   |--- lag_1 <= 68.53\n",
      "|   |   |   |   |   |--- value: [73.15]\n",
      "|   |   |   |   |--- lag_1 >  68.53\n",
      "|   |   |   |   |   |--- value: [78.83]\n",
      "|   |   |   |--- lag_1 >  78.91\n",
      "|   |   |   |   |--- lag_6 <= 83.21\n",
      "|   |   |   |   |   |--- value: [85.04]\n",
      "|   |   |   |   |--- lag_6 >  83.21\n",
      "|   |   |   |   |   |--- value: [89.09]\n",
      "|   |   |--- lag_6 >  90.78\n",
      "|   |   |   |--- lag_1 <= 81.92\n",
      "|   |   |   |   |--- lag_1 <= 78.01\n",
      "|   |   |   |   |   |--- value: [82.53]\n",
      "|   |   |   |   |--- lag_1 >  78.01\n",
      "|   |   |   |   |   |--- value: [86.89]\n",
      "|   |   |   |--- lag_1 >  81.92\n",
      "|   |   |   |   |--- ma_feat <= 91.12\n",
      "|   |   |   |   |   |--- value: [97.69]\n",
      "|   |   |   |   |--- ma_feat >  91.12\n",
      "|   |   |   |   |   |--- value: [91.92]\n",
      "|--- lag_6 >  94.84\n",
      "|   |--- lag_5 <= 94.43\n",
      "|   |   |--- lag_2 <= 78.04\n",
      "|   |   |   |--- lag_2 <= 75.26\n",
      "|   |   |   |   |--- value: [88.45]\n",
      "|   |   |   |--- lag_2 >  75.26\n",
      "|   |   |   |   |--- value: [85.96]\n",
      "|   |   |--- lag_2 >  78.04\n",
      "|   |   |   |--- lag_5 <= 92.87\n",
      "|   |   |   |   |--- lag_7 <= 108.67\n",
      "|   |   |   |   |   |--- value: [96.73]\n",
      "|   |   |   |   |--- lag_7 >  108.67\n",
      "|   |   |   |   |   |--- value: [99.68]\n",
      "|   |   |   |--- lag_5 >  92.87\n",
      "|   |   |   |   |--- lag_4 <= 87.81\n",
      "|   |   |   |   |   |--- value: [103.36]\n",
      "|   |   |   |   |--- lag_4 >  87.81\n",
      "|   |   |   |   |   |--- value: [99.17]\n",
      "|   |--- lag_5 >  94.43\n",
      "|   |   |--- lag_2 <= 88.39\n",
      "|   |   |   |--- lag_1 <= 89.32\n",
      "|   |   |   |   |--- sin_dow <= 0.22\n",
      "|   |   |   |   |   |--- value: [90.78]\n",
      "|   |   |   |   |--- sin_dow >  0.22\n",
      "|   |   |   |   |   |--- value: [97.45]\n",
      "|   |   |   |--- lag_1 >  89.32\n",
      "|   |   |   |   |--- lag_1 <= 98.37\n",
      "|   |   |   |   |   |--- value: [102.77]\n",
      "|   |   |   |   |--- lag_1 >  98.37\n",
      "|   |   |   |   |   |--- value: [108.63]\n",
      "|   |   |--- lag_2 >  88.39\n",
      "|   |   |   |--- lag_1 <= 105.10\n",
      "|   |   |   |   |--- cos_dow <= 0.20\n",
      "|   |   |   |   |   |--- value: [110.00]\n",
      "|   |   |   |   |--- cos_dow >  0.20\n",
      "|   |   |   |   |   |--- value: [105.12]\n",
      "|   |   |   |--- lag_1 >  105.10\n",
      "|   |   |   |   |--- lag_5 <= 103.64\n",
      "|   |   |   |   |   |--- value: [109.77]\n",
      "|   |   |   |   |--- lag_5 >  103.64\n",
      "|   |   |   |   |   |--- value: [115.92]\n",
      "\n",
      "[Tree Model] Test MAPE for horizon 7 days: 2.38%\n",
      "\n",
      "[Tree Model] Forecast Horizon: 9 days\n",
      "  Candidate Lag L=3: Validation MAPE = 1.88%\n",
      "  Candidate Lag L=5: Validation MAPE = 1.36%\n",
      "  Candidate Lag L=7: Validation MAPE = 1.45%\n",
      "  Candidate Lag L=9: Validation MAPE = 2.50%\n",
      "--> Best Lag for horizon 9 days: L = 5 with Validation MAPE = 1.36%\n",
      "Decision Tree Rules:\n",
      "|--- lag_1 <= 88.51\n",
      "|   |--- lag_1 <= 79.32\n",
      "|   |   |--- lag_5 <= 73.95\n",
      "|   |   |   |--- lag_1 <= 68.06\n",
      "|   |   |   |   |--- lag_5 <= 60.65\n",
      "|   |   |   |   |   |--- value: [59.30]\n",
      "|   |   |   |   |--- lag_5 >  60.65\n",
      "|   |   |   |   |   |--- value: [64.95]\n",
      "|   |   |   |--- lag_1 >  68.06\n",
      "|   |   |   |   |--- lag_1 <= 76.35\n",
      "|   |   |   |   |   |--- value: [69.65]\n",
      "|   |   |   |   |--- lag_1 >  76.35\n",
      "|   |   |   |   |   |--- value: [73.93]\n",
      "|   |   |--- lag_5 >  73.95\n",
      "|   |   |   |--- lag_1 <= 71.13\n",
      "|   |   |   |   |--- lag_5 <= 74.18\n",
      "|   |   |   |   |   |--- value: [84.19]\n",
      "|   |   |   |   |--- lag_5 >  74.18\n",
      "|   |   |   |   |   |--- value: [71.73]\n",
      "|   |   |   |--- lag_1 >  71.13\n",
      "|   |   |   |   |--- lag_2 <= 80.23\n",
      "|   |   |   |   |   |--- value: [81.38]\n",
      "|   |   |   |   |--- lag_2 >  80.23\n",
      "|   |   |   |   |   |--- value: [76.05]\n",
      "|   |--- lag_1 >  79.32\n",
      "|   |   |--- lag_5 <= 82.78\n",
      "|   |   |   |--- lag_2 <= 78.90\n",
      "|   |   |   |   |--- lag_4 <= 71.71\n",
      "|   |   |   |   |   |--- value: [80.53]\n",
      "|   |   |   |   |--- lag_4 >  71.71\n",
      "|   |   |   |   |   |--- value: [90.16]\n",
      "|   |   |   |--- lag_2 >  78.90\n",
      "|   |   |   |   |--- lag_1 <= 87.19\n",
      "|   |   |   |   |   |--- value: [76.66]\n",
      "|   |   |   |   |--- lag_1 >  87.19\n",
      "|   |   |   |   |   |--- value: [82.24]\n",
      "|   |   |--- lag_5 >  82.78\n",
      "|   |   |   |--- lag_5 <= 110.92\n",
      "|   |   |   |   |--- lag_2 <= 86.51\n",
      "|   |   |   |   |   |--- value: [92.01]\n",
      "|   |   |   |   |--- lag_2 >  86.51\n",
      "|   |   |   |   |   |--- value: [87.06]\n",
      "|   |   |   |--- lag_5 >  110.92\n",
      "|   |   |   |   |--- lag_3 <= 98.40\n",
      "|   |   |   |   |   |--- value: [97.24]\n",
      "|   |   |   |   |--- lag_3 >  98.40\n",
      "|   |   |   |   |   |--- value: [99.51]\n",
      "|--- lag_1 >  88.51\n",
      "|   |--- lag_5 <= 93.97\n",
      "|   |   |--- lag_1 <= 100.98\n",
      "|   |   |   |--- lag_2 <= 91.11\n",
      "|   |   |   |   |--- lag_4 <= 75.72\n",
      "|   |   |   |   |   |--- value: [87.30]\n",
      "|   |   |   |   |--- lag_4 >  75.72\n",
      "|   |   |   |   |   |--- value: [98.02]\n",
      "|   |   |   |--- lag_2 >  91.11\n",
      "|   |   |   |   |--- lag_1 <= 94.67\n",
      "|   |   |   |   |   |--- value: [85.84]\n",
      "|   |   |   |   |--- lag_1 >  94.67\n",
      "|   |   |   |   |   |--- value: [89.37]\n",
      "|   |   |--- lag_1 >  100.98\n",
      "|   |   |   |--- lag_1 <= 106.77\n",
      "|   |   |   |   |--- sin_dow <= -0.88\n",
      "|   |   |   |   |   |--- value: [101.63]\n",
      "|   |   |   |   |--- sin_dow >  -0.88\n",
      "|   |   |   |   |   |--- value: [95.37]\n",
      "|   |   |   |--- lag_1 >  106.77\n",
      "|   |   |   |   |--- lag_5 <= 91.95\n",
      "|   |   |   |   |   |--- value: [98.83]\n",
      "|   |   |   |   |--- lag_5 >  91.95\n",
      "|   |   |   |   |   |--- value: [102.92]\n",
      "|   |--- lag_5 >  93.97\n",
      "|   |   |--- lag_3 <= 103.64\n",
      "|   |   |   |--- lag_2 <= 87.79\n",
      "|   |   |   |   |--- ma_feat <= 90.39\n",
      "|   |   |   |   |   |--- value: [100.24]\n",
      "|   |   |   |   |--- ma_feat >  90.39\n",
      "|   |   |   |   |   |--- value: [104.40]\n",
      "|   |   |   |--- lag_2 >  87.79\n",
      "|   |   |   |   |--- lag_1 <= 102.34\n",
      "|   |   |   |   |   |--- value: [107.18]\n",
      "|   |   |   |   |--- lag_1 >  102.34\n",
      "|   |   |   |   |   |--- value: [110.88]\n",
      "|   |   |--- lag_3 >  103.64\n",
      "|   |   |   |--- lag_3 <= 107.47\n",
      "|   |   |   |   |--- lag_2 <= 96.99\n",
      "|   |   |   |   |   |--- value: [89.36]\n",
      "|   |   |   |   |--- lag_2 >  96.99\n",
      "|   |   |   |   |   |--- value: [90.07]\n",
      "|   |   |   |--- lag_3 >  107.47\n",
      "|   |   |   |   |--- lag_1 <= 91.00\n",
      "|   |   |   |   |   |--- value: [91.89]\n",
      "|   |   |   |   |--- lag_1 >  91.00\n",
      "|   |   |   |   |   |--- value: [93.86]\n",
      "\n",
      "[Tree Model] Test MAPE for horizon 9 days: 2.25%\n",
      "\n",
      "Final Results for Tree-Based Model (Forecast Horizon: Best Lag, Test MAPE %):\n",
      "  3 days -> Best Lag: 7, Test MAPE: 3.32%\n",
      "  5 days -> Best Lag: 7, Test MAPE: 2.74%\n",
      "  7 days -> Best Lag: 7, Test MAPE: 2.38%\n",
      "  9 days -> Best Lag: 5, Test MAPE: 2.25%\n",
      "\n",
      "Evaluating OLS-based AR and ARMA Models on Test Set:\n",
      "\n",
      "Forecast Horizon 3 days:\n",
      "  AR(3) Test MAPE:    3.90%\n",
      "  AR(2) Test MAPE:    5.02%\n",
      "  ARMA(1,1) Test MAPE:4.35%\n",
      "\n",
      "Forecast Horizon 5 days:\n",
      "  AR(3) Test MAPE:    2.85%\n",
      "  AR(2) Test MAPE:    4.56%\n",
      "  ARMA(1,1) Test MAPE:3.92%\n",
      "\n",
      "Forecast Horizon 7 days:\n",
      "  AR(3) Test MAPE:    2.70%\n",
      "  AR(2) Test MAPE:    4.85%\n",
      "  ARMA(1,1) Test MAPE:4.23%\n",
      "\n",
      "Forecast Horizon 9 days:\n",
      "  AR(3) Test MAPE:    2.96%\n",
      "  AR(2) Test MAPE:    5.42%\n",
      "  ARMA(1,1) Test MAPE:4.76%\n"
     ]
    }
   ],
   "source": [
    "# ======== Main Code: Data Preparation =========\n",
    "\n",
    "# Read Electric Production data (expects columns: ['DATE','IPG2211A2N'])\n",
    "df = pd.read_csv(r\"https://raw.githubusercontent.com/datalev001/tree_TSM/refs/heads/main/data/Electric_Production_tm.csv\")\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "df = df.sort_values(by='DATE').reset_index(drop=True)\n",
    "df = add_cycle_features(df, date_col=\"DATE\")\n",
    "df['MA_3'] = add_ma_feature(df['IPG2211A2N'], window=3)\n",
    "\n",
    "target_col = \"IPG2211A2N\"\n",
    "date_col = \"DATE\"\n",
    "decay_rate = 0.01\n",
    "candidate_lags = [3, 5, 7, 9]\n",
    "forecast_horizons = [3, 5, 7, 9]\n",
    "\n",
    "# Split data into training and test sets (80% train, 20% test)\n",
    "split_ratio = 0.8\n",
    "split_idx = int(len(df) * split_ratio)\n",
    "train_df = df.iloc[:split_idx].reset_index(drop=True)\n",
    "test_df = df.iloc[split_idx:].reset_index(drop=True)\n",
    "\n",
    "print(\"Total observations:\", len(df))\n",
    "print(\"Training observations:\", len(train_df))\n",
    "print(\"Test observations:\", len(test_df))\n",
    "\n",
    "# --- Tree-Based Forecasting (Using the above functions) ---\n",
    "results_tree = {}\n",
    "for horizon in forecast_horizons:\n",
    "    best_mape = float('inf')\n",
    "    best_L = None\n",
    "    best_model = None\n",
    "    print(f\"\\n[Tree Model] Forecast Horizon: {horizon} days\")\n",
    "    val_start_idx = int(0.8 * len(train_df))\n",
    "    for L in candidate_lags:\n",
    "        X_train, y_train, weights_train, _ = construct_lagged_dataset(train_df, target_col, L, decay_rate, date_col)\n",
    "        tree_model = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "        tree_model.fit(X_train, y_train, sample_weight=weights_train)\n",
    "        mape_val = rolling_forecast_evaluation(tree_model, train_df, target_col, L, horizon, decay_rate, start_idx=val_start_idx)\n",
    "        if mape_val is None:\n",
    "            continue\n",
    "        print(f\"  Candidate Lag L={L}: Validation MAPE = {mape_val:.2f}%\")\n",
    "        if mape_val < best_mape:\n",
    "            best_mape = mape_val\n",
    "            best_L = L\n",
    "            best_model = tree_model\n",
    "    print(f\"--> Best Lag for horizon {horizon} days: L = {best_L} with Validation MAPE = {best_mape:.2f}%\")\n",
    "    X_train_full, y_train_full, weights_train_full, _ = construct_lagged_dataset(train_df, target_col, best_L, decay_rate, date_col)\n",
    "    final_tree_model = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "    final_tree_model.fit(X_train_full, y_train_full, sample_weight=weights_train_full)\n",
    "    \n",
    "    # --------------------------\n",
    "    # Added Output: Print Decision Tree Rules\n",
    "    # --------------------------\n",
    "    from sklearn.tree import export_text\n",
    "    feature_names = [f\"lag_{i}\" for i in range(1, best_L+1)] + [\"sin_dow\", \"cos_dow\", \"ma_feat\"]\n",
    "    tree_rules = export_text(final_tree_model, feature_names=feature_names)\n",
    "    print(\"Decision Tree Rules:\")\n",
    "    print(tree_rules)\n",
    "    # --------------------------\n",
    "    \n",
    "    test_mape_tree = rolling_forecast_evaluation(final_tree_model, test_df, target_col, best_L, horizon, decay_rate, start_idx=best_L)\n",
    "    print(f\"[Tree Model] Test MAPE for horizon {horizon} days: {test_mape_tree:.2f}%\")\n",
    "    results_tree[horizon] = {'Best_Lag': best_L, 'Test_MAPE': test_mape_tree}\n",
    "\n",
    "print(\"\\nFinal Results for Tree-Based Model (Forecast Horizon: Best Lag, Test MAPE %):\")\n",
    "for h in forecast_horizons:\n",
    "    res = results_tree[h]\n",
    "    print(f\"  {h} days -> Best Lag: {res['Best_Lag']}, Test MAPE: {res['Test_MAPE']:.2f}%\")\n",
    "\n",
    "# ======== Additional: OLS-based AR and ARMA Models =========\n",
    "\n",
    "# Prepare test series and cycle exogenous regressors (sin_dow and cos_dow)\n",
    "series_ar = test_df[target_col].reset_index(drop=True)\n",
    "exog_ar = test_df[['sin_dow', 'cos_dow']].reset_index(drop=True)\n",
    "\n",
    "print(\"\\nEvaluating OLS-based AR and ARMA Models on Test Set:\")\n",
    "\n",
    "for horizon in forecast_horizons:\n",
    "    # AR(3) replaces the previous AR(1) candidate; note start_idx is now 3.\n",
    "    mape_ar3 = rolling_forecast_evaluation_ar_ols(series_ar, exog_ar, p=3, forecast_horizon=horizon, start_idx=3)\n",
    "    # AR(2) remains.\n",
    "    mape_ar2 = rolling_forecast_evaluation_ar_ols(series_ar, exog_ar, p=2, forecast_horizon=horizon, start_idx=2)\n",
    "    # ARMA(1,1) remains.\n",
    "    mape_arma11 = rolling_forecast_evaluation_arma_ols(series_ar, exog_ar, forecast_horizon=horizon, start_idx=2)\n",
    "    \n",
    "    print(f\"\\nForecast Horizon {horizon} days:\")\n",
    "    print(f\"  AR(3) Test MAPE:    {mape_ar3:.2f}%\")\n",
    "    print(f\"  AR(2) Test MAPE:    {mape_ar2:.2f}%\")\n",
    "    print(f\"  ARMA(1,1) Test MAPE:{mape_arma11:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
