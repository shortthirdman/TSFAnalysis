{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91ed9ad2-dfc8-4802-a95a-8b044de495dd",
   "metadata": {},
   "source": [
    "### Irregular Time Series for Predictive Modeling — Part I\n",
    "\n",
    "> Transforming, visualizing, and decomposing irregular time series. [Hands-On](https://medium.com/data-science-collective/hands-on-irregular-time-series-pt-i-2b8730bff40b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5067b203-45ab-4552-99f5-06c7d8311725",
   "metadata": {},
   "source": [
    "This section introduces irregular time series, explores the dataset, and applies initial data transformations — like the log transformation to address data skewness.\n",
    "\n",
    "This project explores an intriguing AI application in the real estate market: **predicting property sales using irregular time series modeling**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28f7f6f-c168-4ef0-ad9c-4421922ddc2a",
   "metadata": {},
   "source": [
    "##### Generating the Fictitious Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229fa62e-6a15-4528-b929-828311a3698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Generate random dates from 2011 to 2023\n",
    "def generate_random_dates(start_year, end_year, n_samples):\n",
    "    start_date = datetime(start_year, 1, 1)\n",
    "    end_date = datetime(end_year, 12, 31)\n",
    "    date_range = (end_date - start_date).days\n",
    "    return [start_date + timedelta(days=random.randint(0, date_range)) for _ in range(n_samples)]\n",
    "\n",
    "# Define dataset parameters\n",
    "n_samples = 29580\n",
    "sale_dates = generate_random_dates(2011, 2023, n_samples)\n",
    "prices = np.random.randint(50000, 1000000, size=n_samples)\n",
    "property_types = np.random.choice(['house', 'apartment'], size=n_samples)\n",
    "num_rooms = np.random.randint(1, 6, size=n_samples)\n",
    "\n",
    "# Create fictitious dataset\n",
    "# This is for demonstration purposes and to support the project execution.\n",
    "dataset = pd.DataFrame({\n",
    "    'sale_date': sale_dates,\n",
    "    'price': prices,\n",
    "    'property_type': property_types,\n",
    "    'num_rooms': num_rooms\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "dataset.to_csv('dataset.csv', index=False)\n",
    "\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c845b1-d7a3-4f70-b0c7-55960020d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Install LightGBM package silently\n",
    "!pip install --no-cache-dir --disable-pip-version-check -q plotly lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fbb5e3-a408-4bb5-a692-c92fb617ac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 3. Import sklearn modules for preprocessing and metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# 4. Import statsmodels for statistical analysis\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# 5. Import LightGBM for machine learning models\n",
    "import lightgbm\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# 6. Import sklearn's linear model for regression\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866a6d26-c82e-49e0-9f45-2ecd68dfa85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Load the dataset\n",
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12ea4c7-785b-40f1-8cf8-948c3be32c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Check dataset shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da12dcef-8c37-4d58-81e8-d21d3a730dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Display first rows of data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead8a2c3-6c61-4292-9957-2fa145edc572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Display the last rows of the dataset\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1d75e5-8855-4e98-a817-88230980d5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Check data types of each column\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f3956-83c6-4885-881c-6360812f4bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Display unique values in the property_type column\n",
    "df['property_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ee4954-a675-44a7-8f51-4b5baaa6c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Set sale_date as the index\n",
    "df.index = pd.to_datetime(df.sale_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7695b0f6-d57e-447b-b050-68a3b94450d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Drop the original sale_date column\n",
    "df = df.drop(columns=['sale_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec45cc5-5698-4029-91d7-3c7e739d2f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Display the first rows of the updated dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b37f9e2-c855-4b18-9c83-0cded7527439",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.8f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7dc7ae-b938-435e-8e46-91211f0674fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. P-value for the bedrooms column\n",
    "print(f\"P-value for Bedrooms Column: {adfuller(df['num_rooms'])[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68452f17-f11a-4ee1-815b-a29ca6672141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. P-value for the price column\n",
    "print(f\"P-value for Price Column: {adfuller(df['price'])[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b2b09f-03c5-485d-aba6-001355c094b1",
   "metadata": {},
   "source": [
    "The `price` series is also stationary.\n",
    "\n",
    "Both variables — `num_rooms` and `price` — exhibit the necessary behavior for applying statistical modeling strategies.\n",
    "\n",
    "They pass the stationarity test, even though they are irregular series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0ae343-b270-43ca-8e83-0e315b472848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18. Display dataframe columns\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c86e0e2-c765-430d-9360-d40db992b9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19. Visualizing the price time series with all records\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.line(df, y='price', labels={'index': 'Time', 'price': 'Price'},\n",
    "              title='Price Time Series',\n",
    "              template='simple_white')\n",
    "fig.update_traces(line_color='green')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8489d5-3298-4a05-ba0d-07cb56935e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20. Visualizing the price time series with the first 300 records\n",
    "fig = px.line(df.iloc[:300], y='price', labels={'index': 'Time', 'price': 'Price'},\n",
    "              title='Price Time Series (First 300 Records)',\n",
    "              template='simple_white')\n",
    "fig.update_traces(line_color='red')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81651e17-55ac-4493-bd71-c5611c09317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21. Scatter plot between price and number of rooms\n",
    "fig = px.scatter(df, x='num_rooms', y='price',\n",
    "                 labels={'num_rooms': 'Number of Rooms', 'price': 'Price (in Thousands)'},\n",
    "                 title='Price vs. Number of Rooms',\n",
    "                 template='simple_white')\n",
    "fig.update_yaxes(tickprefix=\"$\", tickformat=\",.0f\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf738f3-4135-457c-afe6-5ebc7ed2a746",
   "metadata": {},
   "source": [
    "By reducing the view to 300 records, the irregularity becomes more evident.\n",
    "\n",
    "- The green graph (full data) suggests a smoother trend.\n",
    "- The red graph (first 300 records) clearly shows irregularities.\n",
    "\n",
    "There's no clear pattern, trend, or seasonality in the red graph. The line fluctuates with highs, lows, and breaks — an expected behavior in the real estate market.\n",
    "\n",
    "Unlike regular consumer products, real estate sales are irregular. An agency might go weeks without sales, then close multiple deals in a short period.\n",
    "\n",
    "This detailed, segmented analysis helps identify patterns and potential issues more effectively than just viewing the complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a769c17-cd82-4527-bcdf-118b69d4a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. P-value for the number_of_rooms column\n",
    "print(f\"P-value for Number of Rooms Column: {adfuller(df['num_rooms'])[1]}\")\n",
    "\n",
    "# 17. P-value for the price column\n",
    "print(f\"P-value for Price Column: {adfuller(df['price'])[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6481f634-380c-4e10-99cf-7e26a86c46c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22. Boxplot of the price variable\n",
    "fig = px.box(df, y='price',\n",
    "             labels={'price': 'Price (in Thousands)'},\n",
    "             title='Price Distribution',\n",
    "             template='simple_white')\n",
    "fig.update_yaxes(tickprefix=\"$\", tickformat=\".2s\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959a0491-ac43-40be-8f6b-5955b7ee60c4",
   "metadata": {},
   "source": [
    "The boxplot displays the median, quartiles, maximum/minimum values, and outliers.\n",
    "\n",
    "The distribution is skewed, with a flattened box — unlike the expected, more expanded shape.\n",
    "\n",
    "The median price is around 550 thousand.\n",
    "However, there are several outliers reaching up to 8 million."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d1e35f-ef13-4e9e-9097-59564ed6fbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23. Histogram of the price variable\n",
    "fig = px.histogram(df, x='price',\n",
    "                   labels={'price': 'Price (in Thousands)'},\n",
    "                   title='Price Distribution Histogram',\n",
    "                   template='simple_white')\n",
    "fig.update_xaxes(tickprefix=\"$\", tickformat=\".2s\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f789e6-7fc9-4c66-8a14-7e80fcff230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24. Apply log transformation to the price variable\n",
    "import numpy as np\n",
    "\n",
    "df['log_price'] = np.log(df['price'])\n",
    "\n",
    "# 25. Histogram of the log-transformed price variable\n",
    "fig = px.histogram(df, x='log_price',\n",
    "                   labels={'log_price': 'Log of Price'},\n",
    "                   title='Histogram of Log-Transformed Price',\n",
    "                   template='simple_white')\n",
    "fig.update_xaxes(title_text='Log of Price')\n",
    "fig.update_yaxes(title_text='Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6bddba-f97b-4a35-a7ab-4b579a25756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26. Line plot of the log-transformed price variable\n",
    "fig = px.line(df, y='log_price',\n",
    "              labels={'index': 'Time', 'log_price': 'Log of Price'},\n",
    "              title='Log-Transformed Price Over Time',\n",
    "              template='simple_white')\n",
    "fig.update_traces(line_color='blue')\n",
    "fig.update_xaxes(title_text='Time')\n",
    "fig.update_yaxes(title_text='Log of Price')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b64c32a-f88d-45c4-a838-d5ae3bb24765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28. Apply encoding to the property type variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df['property_type'] = LabelEncoder().fit_transform(df['property_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29449ac9-dfc8-4b83-b003-b5e3f5dacca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29. Resample the series to monthly and calculate the mean\n",
    "df = df.resample('ME').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa21301-0935-4ea9-a517-a66d5c47cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30. Display the first 10 rows of the dataset\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3d4d67-387d-4bfb-845d-279d5a8b32c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 31. Remove the property type variable as it cannot be grouped adequately by month\n",
    "df.drop('property_type', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5ee05e-9c7d-49b8-8dec-7ae695e3d2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32. Round the values of the num_rooms variable\n",
    "df['num_rooms'] = df['num_rooms'].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a2113d-8107-4a31-a3e7-d1b8b581a35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 33. Remove rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# 34. Display the first rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# 35. Display the last rows of the dataset\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec8069c-8e97-4782-a96a-ad9eae55d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 36. Decompose the price series to analyze trend, seasonality, and residuals\n",
    "result = seasonal_decompose(df['price'])\n",
    "\n",
    "# 37. Plot the decomposition results\n",
    "result.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e146f088-833b-4c73-87ee-869b2b449cdc",
   "metadata": {},
   "source": [
    "### Irregular Time Series for Predictive Modeling — Part II\n",
    "\n",
    "> Feature Engineering, Model Training, and Forecasting Strategies [Hands-On](https://medium.com/data-science-collective/hands-on-irregular-time-series-for-predictive-modeling-part-ii-e5070e721bd6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8c9e77-a744-42cc-875d-04e20b196b78",
   "metadata": {},
   "source": [
    "- **Feature Engineering:** Creating time-based features (like year and month) to enrich the dataset.\n",
    "\n",
    "- **Data Preparation:** Structuring the data for effective model training.\n",
    "\n",
    "- **Model Development:** Building and comparing machine learning models — starting with simple benchmarks and progressing to more refined approaches.\n",
    "\n",
    "- **Forecasting:** Using the trained models to make future price predictions.\n",
    "\n",
    "The goal is to develop accurate and interpretable models for real estate price forecasting, ensuring that complexity is added only when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09f2f93-003d-4c04-8693-a3937ab79bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 43. Extract year and month for feature engineering\n",
    "df['year'] = df.index.year\n",
    "df['month'] = df.index.month\n",
    "\n",
    "# 44. Display the first records to validate the new features\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3306cdce-7970-4479-bc91-bfa7380a66cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 45. Create the index for 70/30 split\n",
    "index = int(len(df) * .7)\n",
    "\n",
    "# 46. Display the dataset length and split index\n",
    "print(len(df), index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ced859-9ecb-47c0-b5f3-b2fab78a7711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 47. Training data (maintaining sequence)\n",
    "train_data = df.iloc[:index]\n",
    "\n",
    "# 48. Display the last record of the training data\n",
    "train_data.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf21abc5-5a8b-4295-95b5-e0375bfc2114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 49. Testing data (maintaining sequence)\n",
    "test_data = df.iloc[index:]\n",
    "\n",
    "# 50. Display the first record of the testing data\n",
    "test_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391708ca-eb3b-4115-8e39-9987cd5deb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 51. Display the last record of the testing data\n",
    "test_data.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f8b25-5c84-4dfb-8638-4ff402174674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 54. The target variable 'price' is what we want to predict\n",
    "y_train = train_data[['log_price']]\n",
    "\n",
    "# 55. Display the first records of the target training data\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e87e27c-f9d9-4f9d-8848-ea24e529a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 54. The target variable 'price' is what we want to predict\n",
    "y_train = train_data[['log_price']]\n",
    "\n",
    "# 55. Display the first records of the target training data\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97678a89-710c-4fc6-8e88-8cd89c63e1aa",
   "metadata": {},
   "source": [
    "#### Building the First Version of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962697d9-2c65-4e59-8f0b-d16ac1a7d869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 56. Create the model\n",
    "model_v1 = LGBMRegressor()\n",
    "\n",
    "# 57. Train the model using the log-transformed target\n",
    "model_v1.fit(X_train, y_train['log_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05033e30-85dc-4130-9e6e-a38c18502a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 58. Prepare test data for input and output\n",
    "X_test = test_data.drop(columns=['log_price'])\n",
    "y_test = test_data[['log_price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eedaf1a-bea6-476b-9d20-f2b0a4c87d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 59. Generate predictions with the test data\n",
    "predictions_v1 = model_v1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d0d3b2-1f3d-4ad6-9ac0-1f05c5a88fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60. Apply the inverse log transformation to the predictions\n",
    "predictions_v1 = np.exp(predictions_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24057c8f-ede7-46df-af1d-aa47ea66c874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 61. Apply the inverse log transformation to the real test data\n",
    "y_test = np.exp(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5a1a17-47b9-4866-9a46-06cd7c66762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# 62. Calculate Mean Absolute Error\n",
    "mae = mean_absolute_error(y_test, predictions_v1)\n",
    "print(f'Mean Absolute Error: {mae:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e543108-1217-448a-bcb2-dc8a4347ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# 63. Advanced Plot with Plotly\n",
    "fig = go.Figure()\n",
    "# Add actual values trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    y=y_test.values.flatten(),\n",
    "    mode='lines',\n",
    "    name='Actual',\n",
    "    line=dict(color='firebrick', width=2),\n",
    "))\n",
    "# Add predicted values trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    y=predictions_v1,\n",
    "    mode='lines',\n",
    "    name='Predicted',\n",
    "    line=dict(color='royalblue', width=2, dash='dash'),\n",
    "))\n",
    "# Customize layout for clarity and style\n",
    "fig.update_layout(\n",
    "    title='Actual vs Predicted Prices',\n",
    "    xaxis_title='Time Index',\n",
    "    yaxis_title='Price',\n",
    "    template='simple_white',\n",
    "    width=900,\n",
    "    height=500,\n",
    "    font=dict(size=12),\n",
    "    legend=dict(title='Legend', orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ac3524-6894-45d5-8ef7-34ebae63f8e1",
   "metadata": {},
   "source": [
    "#### Building the Second Version of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6bc27c-a878-4610-942d-a5f5195deb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 64. Create the model\n",
    "model_v2 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12456eb8-91c1-415f-a7d7-ed7fd2d80641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 65. Train the model using the training data\n",
    "model_v2.fit(X_train, y_train['log_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a14ffc-b056-463e-902c-aa506dcc0bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 66. Prepare input and output data for testing\n",
    "X_test = test_data.drop(columns=['log_price'])\n",
    "y_test = test_data[['log_price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf17f12-59e5-485f-b192-57d6a81fd3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 67. Generate predictions using the test data\n",
    "predictions_v2 = model_v2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e395fe-2ac9-4612-b6b3-1502c9335fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 68. Apply inverse log transformation to the predictions\n",
    "predictions_v2 = np.exp(predictions_v2)\n",
    "\n",
    "# 69. Apply inverse log transformation to the real test data\n",
    "y_test = np.exp(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd42f2a-656a-40f6-bad7-58723061a47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70. Calculate Mean Absolute Error\n",
    "mae = mean_absolute_error(y_test, predictions_v2)\n",
    "print(f'Mean Absolute Error: {mae:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6914881-fef2-4de0-b4bf-d32be20d038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import joblib\n",
    "\n",
    "# 71. Advanced Plot with Plotly\n",
    "fig = go.Figure()\n",
    "# Add actual values trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    y=y_test.values.flatten(),\n",
    "    mode='lines',\n",
    "    name='Actual',\n",
    "    line=dict(color='firebrick', width=2),\n",
    "))\n",
    "# Add predicted values trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    y=predictions_v2,\n",
    "    mode='lines',\n",
    "    name='Predicted',\n",
    "    line=dict(color='royalblue', width=2, dash='dash'),\n",
    "))\n",
    "# Customize layout for clarity and style\n",
    "fig.update_layout(\n",
    "    title='Actual vs Predicted Prices',\n",
    "    xaxis_title='Time Index',\n",
    "    yaxis_title='Price',\n",
    "    template='simple_white',\n",
    "    width=900,\n",
    "    height=500,\n",
    "    font=dict(size=12),\n",
    "    legend=dict(title='Legend', orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f4a8d0-cae5-4e43-9b8b-d2f76fa049f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 72. Import necessary libraries\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# 73. Create the directory if it doesn't exist\n",
    "os.makedirs('model', exist_ok=True)\n",
    "\n",
    "# 74. Define the filename for saving the model\n",
    "filename = 'model/model_v2.sav'\n",
    "\n",
    "# 75. Save the model to disk\n",
    "joblib.dump(model_v2, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336f1366-5c78-4d5a-93ef-2e3210b1fc16",
   "metadata": {},
   "source": [
    "#### Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7167d4-3c18-4ca6-a070-7082bd11855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 76. Display the last record of the test input data\n",
    "X_test.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5b08d6-c08f-4ca4-bbfb-cd7a12a11e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 77. Display the last record from the test input data\n",
    "y_test.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db16146-d792-4206-8289-9a5f52961c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 78. Prepare new data for the forecast\n",
    "new_data = {\n",
    "    'num_rooms': [4.0],\n",
    "    'year': [2023],\n",
    "    'month': [8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516d34c5-414e-4412-9012-f661d472504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 79. Create the date index for the new record\n",
    "date_index = pd.to_datetime('2023-08-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d7bfb-cd94-4db8-98ac-1da41388599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80. Create DataFrame for the new forecast input\n",
    "input_forecast_data = pd.DataFrame({\n",
    "    'price': [0],  # Dummy column to match the training data\n",
    "    'num_rooms': [4.0],\n",
    "    'year': [2023],\n",
    "    'month': [8]\n",
    "}, index=[date_index])\n",
    "\n",
    "# 81. Display the prepared forecast\n",
    "input_forecast_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de30f600-ae2c-4701-911d-e1583a906200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 82. Load the saved model from disk\n",
    "import joblib\n",
    "model_v2 = joblib.load('model/model_v2.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb28cb12-a4d1-4582-a96a-38f63c739613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 83. Generate the forecast using the model\n",
    "forecast = model_v2.predict(input_forecast_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0066436-247b-4a65-b8ae-1af73089ab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 82. Display the forecast (in log scale)\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae0c32d-e2b8-4e7c-ab63-7a22bd8ff74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 83. Apply inverse log transformation to get the original price\n",
    "forecast = np.exp(forecast)\n",
    "\n",
    "# 84. Display the transformed forecast\n",
    "forecast"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
